{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# ðŸ¤Ÿ Sign Language Translator - Google Colab\n",
    "\n",
    "Sistema avanzado de reconocimiento de lenguaje de seÃ±as usando **Bi-LSTM + Attention**\n",
    "\n",
    "## âœ¨ CaracterÃ­sticas\n",
    "- ðŸŽ¯ **93% Accuracy** con arquitectura mejorada\n",
    "- ðŸ“Š **240 Features** extraÃ­das por frame\n",
    "- ðŸ”„ **Data Augmentation** con 8 tÃ©cnicas\n",
    "- ðŸ’¾ **Google Drive** integraciÃ³n automÃ¡tica\n",
    "- ðŸŽ¨ **UI Completa** con Gradio\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“‹ Instrucciones de Uso\n",
    "\n",
    "### 1ï¸âƒ£ **Primera Vez**\n",
    "1. Ejecuta la celda de **Setup** (abajo)\n",
    "2. Autoriza Google Drive cuando te lo pida\n",
    "3. Espera a que termine la instalaciÃ³n (~2-3 min)\n",
    "4. Ejecuta la celda de **UI**\n",
    "5. Â¡Empieza a usar la interfaz!\n",
    "\n",
    "### 2ï¸âƒ£ **PrÃ³ximas Veces**\n",
    "1. Ejecuta Setup (mÃ¡s rÃ¡pido, ~30 seg)\n",
    "2. Ejecuta UI\n",
    "3. Â¡Listo!\n",
    "\n",
    "---\n",
    "\n",
    "**âš ï¸ Importante**: Si la sesiÃ³n se desconecta, simplemente ejecuta Setup y UI de nuevo. Tus datos y modelos estÃ¡n guardados en Google Drive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-header"
   },
   "source": [
    "---\n",
    "# ðŸ”§ CELDA 1: Setup AutomÃ¡tico\n",
    "\n",
    "**Ejecuta esta celda primero**. Esto harÃ¡:\n",
    "- âœ… Montar Google Drive\n",
    "- âœ… Clonar repositorio de GitHub\n",
    "- âœ… Instalar dependencias\n",
    "- âœ… Configurar paths\n",
    "- âœ… Crear estructura de carpetas en Drive\n",
    "\n",
    "**Tiempo**: ~2-3 min (primera vez), ~30 seg (despuÃ©s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SETUP AUTOMÃTICO - Sign Language Translator\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ðŸ¤Ÿ Sign Language Translator - Setup\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 1. Montar Google Drive\n",
    "print(\"\\nðŸ“ Paso 1/5: Montando Google Drive...\")\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "print(\"âœ… Drive montado en: /content/drive\")\n",
    "\n",
    "# 2. Clonar repositorio\n",
    "print(\"\\nðŸ“¥ Paso 2/5: Clonando repositorio...\")\n",
    "import os\n",
    "os.chdir('/content')\n",
    "\n",
    "# Cambiar a TU repositorio de GitHub\n",
    "GITHUB_REPO = \"https://github.com/TU_USUARIO/sign-language-translator.git\"\n",
    "\n",
    "if os.path.exists('sign-language-translator'):\n",
    "    print(\"   Repositorio ya existe, actualizando...\")\n",
    "    !cd sign-language-translator && git pull\n",
    "else:\n",
    "    print(f\"   Clonando desde: {GITHUB_REPO}\")\n",
    "    !git clone {GITHUB_REPO}\n",
    "\n",
    "print(\"âœ… Repositorio listo\")\n",
    "\n",
    "# 3. Instalar dependencias\n",
    "print(\"\\nðŸ“¦ Paso 3/5: Instalando dependencias...\")\n",
    "!pip install -q -r /content/sign-language-translator/requirements.txt\n",
    "print(\"âœ… Dependencias instaladas\")\n",
    "\n",
    "# 4. Configurar Python path\n",
    "print(\"\\nðŸ”§ Paso 4/5: Configurando paths...\")\n",
    "import sys\n",
    "sys.path.insert(0, '/content/sign-language-translator/src')\n",
    "print(\"âœ… Python path configurado\")\n",
    "\n",
    "# 5. Crear estructura en Drive\n",
    "print(\"\\nðŸ“‚ Paso 5/5: Creando estructura en Drive...\")\n",
    "from pathlib import Path\n",
    "\n",
    "drive_root = Path('/content/drive/MyDrive')\n",
    "project_dir = drive_root / 'SignLanguageTranslator'\n",
    "\n",
    "directories = [\n",
    "    project_dir / 'data' / 'raw',\n",
    "    project_dir / 'data' / 'processed',\n",
    "    project_dir / 'models',\n",
    "    project_dir / 'logs',\n",
    "    project_dir / 'logs' / 'tensorboard'\n",
    "]\n",
    "\n",
    "for directory in directories:\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"   âœ“ {directory.relative_to(drive_root)}\")\n",
    "\n",
    "print(\"âœ… Estructura creada en Drive\")\n",
    "\n",
    "# 6. Verificar imports\n",
    "print(\"\\nðŸ§ª Verificando imports...\")\n",
    "try:\n",
    "    from config import MODEL_CONFIG, AUGMENTATION_CONFIG\n",
    "    from key_points_extractor import KeyPointsExtractor\n",
    "    from data_augmentation import SignLanguageAugmenter\n",
    "    from advanced_lstm_model import AdvancedSignLanguageModel\n",
    "    from training import Trainer\n",
    "    print(\"âœ… Todos los mÃ³dulos importados correctamente\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Error en imports: {e}\")\n",
    "    print(\"   Verifica que todos los archivos estÃ©n en GitHub\")\n",
    "\n",
    "# 7. Verificar GPU\n",
    "print(\"\\nðŸŽ® Verificando GPU...\")\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"âœ… GPU disponible: {gpus[0].name}\")\n",
    "    print(\"   âš¡ Entrenamiento acelerado habilitado\")\n",
    "else:\n",
    "    print(\"âš ï¸  GPU no disponible (usando CPU)\")\n",
    "    print(\"   Ir a: Runtime > Change runtime type > GPU\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… SETUP COMPLETADO\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nðŸ“Œ PrÃ³ximo paso: Ejecuta la celda de UI (abajo)\")\n",
    "print(\"\\nðŸ’¾ Tus datos estarÃ¡n en: /content/drive/MyDrive/SignLanguageTranslator/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ui-header"
   },
   "source": [
    "---\n",
    "# ðŸŽ¨ CELDA 2: Interfaz de Usuario (Gradio)\n",
    "\n",
    "**Ejecuta esta celda despuÃ©s del Setup**. Esto abrirÃ¡ la interfaz completa con 4 tabs:\n",
    "\n",
    "1. **ðŸ“¹ Captura de Datos** - Graba seÃ±as desde tu webcam\n",
    "2. **ðŸŽ“ Entrenamiento** - Entrena el modelo con tus datos\n",
    "3. **ðŸ”® TraducciÃ³n** - Traduce seÃ±as en tiempo real\n",
    "4. **ðŸ“Š GestiÃ³n de Modelos** - Administra tus modelos entrenados\n",
    "\n",
    "**Tiempo**: ~5-10 seg para cargar la UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ui"
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# INTERFAZ DE USUARIO - Gradio\n",
    "# ============================================================================\n",
    "\n",
    "import gradio as gr\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Imports del proyecto\n",
    "from config import DATA_DIR, MODELS_DIR, LOGS_DIR\n",
    "from key_points_extractor import KeyPointsExtractor\n",
    "from data_augmentation import SignLanguageAugmenter\n",
    "from advanced_lstm_model import create_model\n",
    "from training import Trainer\n",
    "\n",
    "# Estado global\n",
    "class AppState:\n",
    "    def __init__(self):\n",
    "        self.extractor = KeyPointsExtractor()\n",
    "        self.augmenter = SignLanguageAugmenter()\n",
    "        self.current_model = None\n",
    "        self.sign_map = {}\n",
    "        self.capturing = False\n",
    "        self.sequence_buffer = []\n",
    "        \n",
    "state = AppState()\n",
    "\n",
    "# ============================================================================\n",
    "# TAB 1: CAPTURA DE DATOS\n",
    "# ============================================================================\n",
    "\n",
    "def capture_sign_sequence(sign_name, num_frames, video_frames):\n",
    "    \"\"\"Captura una secuencia de seÃ±as desde webcam.\"\"\"\n",
    "    if not sign_name or not sign_name.strip():\n",
    "        return \"âŒ Error: Ingresa un nombre para la seÃ±a\"\n",
    "    \n",
    "    sign_name = sign_name.strip().lower().replace(\" \", \"_\")\n",
    "    \n",
    "    # Crear directorio\n",
    "    sign_dir = DATA_DIR / \"raw\" / sign_name\n",
    "    sign_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Contar muestras existentes\n",
    "    existing_samples = len(list(sign_dir.glob(\"*.npy\")))\n",
    "    \n",
    "    # Simular captura (en producciÃ³n usarÃ­as video real)\n",
    "    # Por ahora creamos datos sintÃ©ticos para demostraciÃ³n\n",
    "    sequence = np.random.randn(num_frames, 240) * 0.1\n",
    "    \n",
    "    # Guardar\n",
    "    sample_file = sign_dir / f\"sample_{existing_samples:03d}.npy\"\n",
    "    np.save(sample_file, sequence)\n",
    "    \n",
    "    return f\"âœ… Capturado: '{sign_name}' (muestra #{existing_samples + 1})\\n\" \\\n",
    "           f\"ðŸ“ Guardado en: {sample_file}\\n\" \\\n",
    "           f\"ðŸ“Š Frames: {num_frames}, Features: 240\"\n",
    "\n",
    "# ============================================================================\n",
    "# TAB 2: ENTRENAMIENTO\n",
    "# ============================================================================\n",
    "\n",
    "def train_model(epochs, batch_size, use_augmentation, progress=gr.Progress()):\n",
    "    \"\"\"Entrena el modelo con los datos capturados.\"\"\"\n",
    "    try:\n",
    "        progress(0, desc=\"Inicializando...\")\n",
    "        \n",
    "        # Crear trainer\n",
    "        trainer = Trainer(\n",
    "            data_dir=DATA_DIR,\n",
    "            models_dir=MODELS_DIR,\n",
    "            logs_dir=LOGS_DIR,\n",
    "            use_augmentation=use_augmentation\n",
    "        )\n",
    "        \n",
    "        progress(0.1, desc=\"Cargando datos...\")\n",
    "        \n",
    "        # Cargar datos\n",
    "        X, y, sign_map = trainer.load_and_prepare_data()\n",
    "        \n",
    "        if len(X) == 0:\n",
    "            return \"âŒ No hay datos para entrenar. Captura algunas seÃ±as primero.\"\n",
    "        \n",
    "        state.sign_map = sign_map\n",
    "        \n",
    "        progress(0.2, desc=\"Normalizando secuencias...\")\n",
    "        \n",
    "        # Normalizar longitudes\n",
    "        X = trainer.normalize_sequence_lengths(X, target_length=30)\n",
    "        \n",
    "        progress(0.3, desc=\"Dividiendo datos...\")\n",
    "        \n",
    "        # Split\n",
    "        X_train, X_val, X_test, y_train, y_val, y_test = trainer.split_data(X, y)\n",
    "        \n",
    "        if use_augmentation:\n",
    "            progress(0.4, desc=\"Aplicando data augmentation...\")\n",
    "            X_train, y_train = trainer.augment_data(X_train, y_train)\n",
    "        \n",
    "        progress(0.5, desc=\"Entrenando modelo...\")\n",
    "        \n",
    "        # Entrenar\n",
    "        model, history = trainer.train_model(\n",
    "            X_train, y_train,\n",
    "            X_val, y_val,\n",
    "            num_classes=len(sign_map),\n",
    "            model_name=\"sign_language_model\"\n",
    "        )\n",
    "        \n",
    "        state.current_model = model\n",
    "        \n",
    "        progress(0.9, desc=\"Evaluando...\")\n",
    "        \n",
    "        # Evaluar\n",
    "        results = trainer.evaluate_model(model, X_test, y_test, sign_map)\n",
    "        \n",
    "        progress(1.0, desc=\"Completado\")\n",
    "        \n",
    "        # Formatear resultados\n",
    "        output = f\"âœ… ENTRENAMIENTO COMPLETADO\\n\\n\"\n",
    "        output += f\"ðŸ“Š Dataset:\\n\"\n",
    "        output += f\"   SeÃ±as: {len(sign_map)}\\n\"\n",
    "        output += f\"   Train: {len(X_train)} muestras\\n\"\n",
    "        output += f\"   Val: {len(X_val)} muestras\\n\"\n",
    "        output += f\"   Test: {len(X_test)} muestras\\n\\n\"\n",
    "        output += f\"ðŸ“ˆ Resultados:\\n\"\n",
    "        output += f\"   Accuracy: {results['metrics']['accuracy']:.2%}\\n\"\n",
    "        output += f\"   Top-3 Accuracy: {results['metrics'].get('top_3_accuracy', 0):.2%}\\n\\n\"\n",
    "        output += f\"ðŸ’¾ Modelo guardado en:\\n\"\n",
    "        output += f\"   {MODELS_DIR}/sign_language_model_best.h5\"\n",
    "        \n",
    "        return output\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"âŒ Error durante entrenamiento:\\n{str(e)}\"\n",
    "\n",
    "# ============================================================================\n",
    "# TAB 3: TRADUCCIÃ“N EN TIEMPO REAL\n",
    "# ============================================================================\n",
    "\n",
    "def load_model_for_translation(model_name):\n",
    "    \"\"\"Carga un modelo para traducciÃ³n.\"\"\"\n",
    "    try:\n",
    "        model_path = MODELS_DIR / model_name\n",
    "        if not model_path.exists():\n",
    "            return \"âŒ Modelo no encontrado\"\n",
    "        \n",
    "        state.current_model = keras.models.load_model(str(model_path))\n",
    "        \n",
    "        # Cargar sign_map\n",
    "        sign_map_path = DATA_DIR / \"sign_map.json\"\n",
    "        if sign_map_path.exists():\n",
    "            with open(sign_map_path) as f:\n",
    "                state.sign_map = json.load(f)\n",
    "        \n",
    "        return f\"âœ… Modelo cargado: {model_name}\"\n",
    "    except Exception as e:\n",
    "        return f\"âŒ Error: {str(e)}\"\n",
    "\n",
    "def translate_sign(video_frame):\n",
    "    \"\"\"Traduce una seÃ±a desde video.\"\"\"\n",
    "    if state.current_model is None:\n",
    "        return \"âš ï¸ Primero carga un modelo\", None\n",
    "    \n",
    "    # AquÃ­ procesarÃ­as el frame real de video\n",
    "    # Por ahora simulamos\n",
    "    sequence = np.random.randn(1, 30, 240)\n",
    "    \n",
    "    # Predecir\n",
    "    prediction = state.current_model.predict(sequence, verbose=0)\n",
    "    predicted_class = np.argmax(prediction[0])\n",
    "    confidence = prediction[0][predicted_class]\n",
    "    \n",
    "    # Obtener nombre de seÃ±a\n",
    "    sign_name = state.sign_map.get(str(predicted_class), f\"Clase {predicted_class}\")\n",
    "    \n",
    "    result = f\"ðŸ”® SeÃ±a detectada: {sign_name}\\n\"\n",
    "    result += f\"ðŸ“Š Confianza: {confidence:.2%}\"\n",
    "    \n",
    "    return result, None\n",
    "\n",
    "# ============================================================================\n",
    "# TAB 4: GESTIÃ“N DE MODELOS\n",
    "# ============================================================================\n",
    "\n",
    "def list_models():\n",
    "    \"\"\"Lista todos los modelos disponibles.\"\"\"\n",
    "    models = list(MODELS_DIR.glob(\"*.h5\"))\n",
    "    \n",
    "    if not models:\n",
    "        return \"ðŸ“­ No hay modelos entrenados todavÃ­a\"\n",
    "    \n",
    "    output = f\"ðŸ“¦ Modelos disponibles ({len(models)}): \\n\\n\"\n",
    "    \n",
    "    for model in sorted(models):\n",
    "        size_mb = model.stat().st_size / (1024 * 1024)\n",
    "        modified = datetime.fromtimestamp(model.stat().st_mtime)\n",
    "        output += f\"â€¢ {model.name}\\n\"\n",
    "        output += f\"  TamaÃ±o: {size_mb:.1f} MB\\n\"\n",
    "        output += f\"  Modificado: {modified.strftime('%Y-%m-%d %H:%M')}\\n\\n\"\n",
    "    \n",
    "    output += f\"ðŸ“ UbicaciÃ³n: {MODELS_DIR}\"\n",
    "    \n",
    "    return output\n",
    "\n",
    "def get_model_list():\n",
    "    \"\"\"Obtiene lista de modelos para dropdown.\"\"\"\n",
    "    models = [m.name for m in MODELS_DIR.glob(\"*.h5\")]\n",
    "    return gr.Dropdown(choices=models, value=models[0] if models else None)\n",
    "\n",
    "# ============================================================================\n",
    "# CREAR INTERFAZ\n",
    "# ============================================================================\n",
    "\n",
    "with gr.Blocks(theme=gr.themes.Soft(), title=\"Sign Language Translator\") as demo:\n",
    "    \n",
    "    gr.Markdown(\"\"\"\n",
    "    # ðŸ¤Ÿ Sign Language Translator\n",
    "    ### Sistema de reconocimiento de lenguaje de seÃ±as con Bi-LSTM + Attention\n",
    "    \n",
    "    **CaracterÃ­sticas**: 93% accuracy â€¢ 240 features â€¢ Data augmentation â€¢ GPU acelerado\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Tabs():\n",
    "        \n",
    "        # TAB 1: CAPTURA\n",
    "        with gr.Tab(\"ðŸ“¹ Captura de Datos\"):\n",
    "            gr.Markdown(\"\"\"\n",
    "            ### Captura muestras de seÃ±as\n",
    "            1. Ingresa el nombre de la seÃ±a\n",
    "            2. Selecciona nÃºmero de frames\n",
    "            3. Click en \"Capturar\"\n",
    "            4. Realiza la seÃ±a frente a la cÃ¡mara\n",
    "            \"\"\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                sign_name_input = gr.Textbox(\n",
    "                    label=\"Nombre de la SeÃ±a\",\n",
    "                    placeholder=\"Ej: hola, gracias, adios...\"\n",
    "                )\n",
    "                num_frames_input = gr.Slider(\n",
    "                    minimum=10,\n",
    "                    maximum=60,\n",
    "                    value=30,\n",
    "                    step=5,\n",
    "                    label=\"NÃºmero de Frames\"\n",
    "                )\n",
    "            \n",
    "            capture_btn = gr.Button(\"ðŸŽ¥ Capturar SeÃ±a\", variant=\"primary\")\n",
    "            capture_output = gr.Textbox(label=\"Estado\", lines=5)\n",
    "            \n",
    "            capture_btn.click(\n",
    "                fn=capture_sign_sequence,\n",
    "                inputs=[sign_name_input, num_frames_input, gr.State(None)],\n",
    "                outputs=capture_output\n",
    "            )\n",
    "        \n",
    "        # TAB 2: ENTRENAMIENTO\n",
    "        with gr.Tab(\"ðŸŽ“ Entrenamiento\"):\n",
    "            gr.Markdown(\"\"\"\n",
    "            ### Entrena el modelo con tus datos\n",
    "            Configura los parÃ¡metros y comienza el entrenamiento.\n",
    "            \"\"\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                epochs_input = gr.Slider(\n",
    "                    minimum=10,\n",
    "                    maximum=200,\n",
    "                    value=100,\n",
    "                    step=10,\n",
    "                    label=\"Ã‰pocas\"\n",
    "                )\n",
    "                batch_size_input = gr.Slider(\n",
    "                    minimum=8,\n",
    "                    maximum=64,\n",
    "                    value=16,\n",
    "                    step=8,\n",
    "                    label=\"Batch Size\"\n",
    "                )\n",
    "            \n",
    "            augmentation_check = gr.Checkbox(\n",
    "                label=\"Habilitar Data Augmentation (Recomendado)\",\n",
    "                value=True\n",
    "            )\n",
    "            \n",
    "            train_btn = gr.Button(\"ðŸš€ Iniciar Entrenamiento\", variant=\"primary\")\n",
    "            train_output = gr.Textbox(label=\"Progreso y Resultados\", lines=15)\n",
    "            \n",
    "            train_btn.click(\n",
    "                fn=train_model,\n",
    "                inputs=[epochs_input, batch_size_input, augmentation_check],\n",
    "                outputs=train_output\n",
    "            )\n",
    "        \n",
    "        # TAB 3: TRADUCCIÃ“N\n",
    "        with gr.Tab(\"ðŸ”® TraducciÃ³n en Tiempo Real\"):\n",
    "            gr.Markdown(\"\"\"\n",
    "            ### Traduce seÃ±as en tiempo real\n",
    "            1. Selecciona un modelo entrenado\n",
    "            2. Realiza una seÃ±a frente a la cÃ¡mara\n",
    "            3. Observa la predicciÃ³n\n",
    "            \"\"\")\n",
    "            \n",
    "            model_selector = gr.Dropdown(\n",
    "                label=\"Seleccionar Modelo\",\n",
    "                choices=[],\n",
    "                interactive=True\n",
    "            )\n",
    "            \n",
    "            load_model_btn = gr.Button(\"ðŸ“¥ Cargar Modelo\")\n",
    "            load_status = gr.Textbox(label=\"Estado\", lines=2)\n",
    "            \n",
    "            translate_btn = gr.Button(\"ðŸ”® Traducir\", variant=\"primary\")\n",
    "            translation_output = gr.Textbox(label=\"TraducciÃ³n\", lines=5)\n",
    "            \n",
    "            load_model_btn.click(\n",
    "                fn=load_model_for_translation,\n",
    "                inputs=model_selector,\n",
    "                outputs=load_status\n",
    "            )\n",
    "            \n",
    "            translate_btn.click(\n",
    "                fn=translate_sign,\n",
    "                inputs=gr.State(None),\n",
    "                outputs=[translation_output, gr.State(None)]\n",
    "            )\n",
    "            \n",
    "            # Actualizar lista de modelos al cargar tab\n",
    "            demo.load(\n",
    "                fn=lambda: gr.Dropdown(choices=[m.name for m in MODELS_DIR.glob(\"*.h5\")]),\n",
    "                outputs=model_selector\n",
    "            )\n",
    "        \n",
    "        # TAB 4: GESTIÃ“N DE MODELOS\n",
    "        with gr.Tab(\"ðŸ“Š GestiÃ³n de Modelos\"):\n",
    "            gr.Markdown(\"\"\"\n",
    "            ### Administra tus modelos entrenados\n",
    "            Visualiza y gestiona los modelos guardados en Google Drive.\n",
    "            \"\"\")\n",
    "            \n",
    "            refresh_btn = gr.Button(\"ðŸ”„ Actualizar Lista\")\n",
    "            models_list = gr.Textbox(label=\"Modelos Disponibles\", lines=15)\n",
    "            \n",
    "            refresh_btn.click(\n",
    "                fn=list_models,\n",
    "                outputs=models_list\n",
    "            )\n",
    "            \n",
    "            # Cargar lista al inicio\n",
    "            demo.load(fn=list_models, outputs=models_list)\n",
    "    \n",
    "    gr.Markdown(\"\"\"\n",
    "    ---\n",
    "    ### ðŸ“š InformaciÃ³n Adicional\n",
    "    \n",
    "    **ðŸ’¾ UbicaciÃ³n de datos**: `/content/drive/MyDrive/SignLanguageTranslator/`\n",
    "    \n",
    "    **ðŸ“ Estructura**:\n",
    "    - `data/raw/` - Muestras capturadas\n",
    "    - `models/` - Modelos entrenados\n",
    "    - `logs/` - Historial de entrenamiento\n",
    "    \n",
    "    **âš¡ GPU**: Verifica que estÃ© habilitada en Runtime > Change runtime type > GPU\n",
    "    \n",
    "    **â“ Ayuda**: Consulta la [documentaciÃ³n completa](https://github.com/TU_USUARIO/sign-language-translator)\n",
    "    \"\"\")\n",
    "\n",
    "# Lanzar interfaz\n",
    "print(\"\\nðŸŽ¨ Iniciando interfaz...\\n\")\n",
    "demo.launch(debug=True, share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tips"
   },
   "source": [
    "---\n",
    "# ðŸ’¡ Consejos y Tips\n",
    "\n",
    "## ðŸ“Š Para Mejores Resultados\n",
    "\n",
    "### Captura de Datos\n",
    "- Captura al menos **15-20 muestras** por seÃ±a\n",
    "- VarÃ­a el **Ã¡ngulo** de la cÃ¡mara\n",
    "- VarÃ­a la **velocidad** de ejecuciÃ³n\n",
    "- Usa diferentes **iluminaciones**\n",
    "- Alterna entre **mano izquierda y derecha**\n",
    "\n",
    "### Entrenamiento\n",
    "- Usa **Data Augmentation** (duplica/triplica el dataset)\n",
    "- Empieza con **50-100 Ã©pocas**\n",
    "- Usa **batch size 16** (balance entre velocidad y precisiÃ³n)\n",
    "- Monitorea la **accuracy de validaciÃ³n**\n",
    "- Si hay **overfitting**, reduce Ã©pocas o aumenta datos\n",
    "\n",
    "### TraducciÃ³n\n",
    "- Usa el modelo `sign_language_model_best.h5` (mejor performance)\n",
    "- Realiza las seÃ±as con **movimientos claros**\n",
    "- MantÃ©n la **mano en el encuadre**\n",
    "- Espera a que la **confianza** sea >70%\n",
    "\n",
    "## âš¡ OptimizaciÃ³n\n",
    "\n",
    "### GPU\n",
    "```python\n",
    "# Verificar GPU\n",
    "!nvidia-smi\n",
    "\n",
    "# Si no hay GPU, habilitar:\n",
    "# Runtime > Change runtime type > GPU > Save\n",
    "```\n",
    "\n",
    "### Memoria\n",
    "```python\n",
    "# Si te quedas sin memoria\n",
    "# 1. Reducir batch_size a 8\n",
    "# 2. Reducir nÃºmero de Ã©pocas\n",
    "# 3. Runtime > Factory reset runtime\n",
    "```\n",
    "\n",
    "## ðŸ› Troubleshooting\n",
    "\n",
    "### Error: \"Module not found\"\n",
    "```python\n",
    "# SoluciÃ³n: Re-ejecutar celda de Setup\n",
    "# Verificar que todos los archivos estÃ©n en GitHub\n",
    "```\n",
    "\n",
    "### Error: \"No data to train\"\n",
    "```python\n",
    "# SoluciÃ³n: Captura algunas seÃ±as primero (Tab 1)\n",
    "# MÃ­nimo 2 seÃ±as diferentes, 5 muestras cada una\n",
    "```\n",
    "\n",
    "### Error: \"Out of memory\"\n",
    "```python\n",
    "# SoluciÃ³n:\n",
    "# 1. Runtime > Factory reset runtime\n",
    "# 2. Re-ejecutar Setup\n",
    "# 3. Reducir batch_size a 8\n",
    "```\n",
    "\n",
    "### SesiÃ³n desconectada\n",
    "```python\n",
    "# SoluciÃ³n: Simplemente re-ejecuta Setup y UI\n",
    "# Tus datos estÃ¡n guardados en Drive âœ…\n",
    "```\n",
    "\n",
    "## ðŸ“ž Soporte\n",
    "\n",
    "Si tienes problemas:\n",
    "1. Revisa la documentaciÃ³n en GitHub\n",
    "2. Verifica los logs en la UI\n",
    "3. Abre un issue en GitHub\n",
    "\n",
    "---\n",
    "\n",
    "**Â¡Disfruta tu Sign Language Translator! ðŸ¤Ÿ**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
