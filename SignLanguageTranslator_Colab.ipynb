{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¤Ÿ Sign Language Translator - VERSIÃ“N COMPLETA\n",
    "\n",
    "## âœ¨ CaracterÃ­sticas Completas\n",
    "- ðŸ“¹ **Webcam en Gradio** (dentro de la interfaz)\n",
    "- ðŸŽ¥ **Captura mÃºltiple** con detecciÃ³n de manos\n",
    "- ðŸŽ“ **Entrenamiento** con Bi-LSTM + Attention\n",
    "- ðŸ”® **TraducciÃ³n** en tiempo real\n",
    "- ðŸ“Š **240 Features** por frame\n",
    "- ðŸ”„ **Data Augmentation**\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“‹ Flujo Completo\n",
    "\n",
    "### 1. Captura (Tab 1)\n",
    "- Webcam en vivo en Gradio\n",
    "- Click \"Preview\" â†’ Ver mano + keypoints\n",
    "- Click \"Capturar\" â†’ Graba mÃºltiples muestras\n",
    "- Auto-pausa sin manos\n",
    "\n",
    "### 2. Entrenamiento (Tab 2)\n",
    "- Carga datos capturados\n",
    "- Entrena Bi-LSTM + Attention\n",
    "- Data augmentation automÃ¡tico\n",
    "- Guarda mejor modelo\n",
    "\n",
    "### 3. TraducciÃ³n (Tab 3)\n",
    "- Carga modelo entrenado\n",
    "- Webcam en tiempo real\n",
    "- Traduce seÃ±as instantÃ¡neamente\n",
    "- Muestra confianza\n",
    "\n",
    "### 4. Dataset Info (Tab 4)\n",
    "- EstadÃ­sticas de datos\n",
    "- Muestras por seÃ±a\n",
    "- Recomendaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ðŸ”§ CELDA 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ðŸ¤Ÿ Sign Language Translator - Setup\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 1. Montar Drive\n",
    "print(\"\\nðŸ“ Paso 1/6: Montando Google Drive...\")\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "print(\"âœ… Drive montado\")\n",
    "\n",
    "# 2. Clonar repo\n",
    "print(\"\\nðŸ“¥ Paso 2/6: Clonando repositorio...\")\n",
    "import os\n",
    "os.chdir('/content')\n",
    "\n",
    "GITHUB_REPO = \"https://github.com/Hernan-Mej/sign-language-translator.git\"\n",
    "\n",
    "if os.path.exists('sign-language-translator'):\n",
    "    !cd sign-language-translator && git pull\n",
    "else:\n",
    "    !git clone {GITHUB_REPO}\n",
    "print(\"âœ… Repositorio listo\")\n",
    "\n",
    "# 3. Instalar deps\n",
    "print(\"\\nðŸ“¦ Paso 3/6: Instalando dependencias...\")\n",
    "!pip install -q protobuf==4.25.8\n",
    "!pip install -q -r /content/sign-language-translator/requirements.txt\n",
    "print(\"âœ… Dependencias instaladas\")\n",
    "\n",
    "# 4. Paths\n",
    "print(\"\\nðŸ”§ Paso 4/6: Configurando paths...\")\n",
    "import sys\n",
    "sys.path.insert(0, '/content/sign-language-translator/src')\n",
    "print(\"âœ… Paths configurados\")\n",
    "\n",
    "# 5. Estructura Drive\n",
    "print(\"\\nðŸ“‚ Paso 5/6: Creando estructura...\")\n",
    "from pathlib import Path\n",
    "\n",
    "drive_root = Path('/content/drive/MyDrive')\n",
    "project_dir = drive_root / 'SignLanguageTranslator'\n",
    "\n",
    "for directory in [\n",
    "    project_dir / 'data' / 'raw',\n",
    "    project_dir / 'data' / 'processed',\n",
    "    project_dir / 'models',\n",
    "    project_dir / 'logs',\n",
    "]:\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"âœ… Estructura creada\")\n",
    "\n",
    "# 6. Verificar imports\n",
    "print(\"\\nðŸ§ª Paso 6/6: Verificando mÃ³dulos...\")\n",
    "try:\n",
    "    from config import MODEL_CONFIG, DATA_DIR, MODELS_DIR\n",
    "    from key_points_extractor import KeyPointsExtractor\n",
    "    from data_augmentation import SignLanguageAugmenter\n",
    "    print(\"âœ… MÃ³dulos bÃ¡sicos OK\")\n",
    "    \n",
    "    # Intentar importar training\n",
    "    try:\n",
    "        from advanced_lstm_model import create_model\n",
    "        from training import Trainer\n",
    "        print(\"âœ… MÃ³dulos de entrenamiento OK\")\n",
    "    except ImportError:\n",
    "        print(\"âš ï¸  MÃ³dulos de entrenamiento no encontrados\")\n",
    "        print(\"   Para entrenar, agrega advanced_lstm_model.py y training.py\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… SETUP COMPLETADO\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nðŸ“Œ Ejecuta la celda de UI (abajo)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ðŸŽ¨ CELDA 2: Interfaz Completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# INTERFAZ COMPLETA CON WEBCAM EN GRADIO\n",
    "# ============================================================================\n",
    "\n",
    "import gradio as gr\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "\n",
    "# Imports del proyecto\n",
    "from config import DATA_DIR, MODELS_DIR, MODEL_CONFIG\n",
    "from key_points_extractor import KeyPointsExtractor\n",
    "from data_augmentation import SignLanguageAugmenter\n",
    "\n",
    "# Intentar importar training\n",
    "try:\n",
    "    from advanced_lstm_model import create_model\n",
    "    from training import Trainer\n",
    "    TRAINING_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TRAINING_AVAILABLE = False\n",
    "    print(\"âš ï¸  MÃ³dulos de entrenamiento no disponibles\")\n",
    "\n",
    "# ============================================================================\n",
    "# ESTADO GLOBAL\n",
    "# ============================================================================\n",
    "\n",
    "class AppState:\n",
    "    def __init__(self):\n",
    "        self.extractor = KeyPointsExtractor()\n",
    "        self.augmenter = SignLanguageAugmenter()\n",
    "        self.current_model = None\n",
    "        self.sign_map = {}\n",
    "        self.capturing = False\n",
    "        self.capture_buffer = []\n",
    "\n",
    "state = AppState()\n",
    "\n",
    "# ============================================================================\n",
    "# FUNCIONES DE PROCESAMIENTO\n",
    "# ============================================================================\n",
    "\n",
    "def process_frame(frame):\n",
    "    \"\"\"Procesa frame con MediaPipe y extrae features.\"\"\"\n",
    "    if frame is None:\n",
    "        return None, np.zeros(240), False\n",
    "    \n",
    "    # Convertir RGB a BGR para OpenCV\n",
    "    frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # Extraer keypoints\n",
    "    processed_frame, features = state.extractor.extract_keypoints(frame_bgr)\n",
    "    \n",
    "    # Detectar si hay mano\n",
    "    hand_detected = not np.all(features == 0)\n",
    "    \n",
    "    # Convertir de vuelta a RGB para Gradio\n",
    "    processed_frame = cv2.cvtColor(processed_frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    return processed_frame, features, hand_detected\n",
    "\n",
    "# ============================================================================\n",
    "# TAB 1: CAPTURA\n",
    "# ============================================================================\n",
    "\n",
    "def preview_webcam(frame):\n",
    "    \"\"\"Preview de webcam con detecciÃ³n.\"\"\"\n",
    "    if frame is None:\n",
    "        return None, \"âš ï¸ No hay frame de webcam\"\n",
    "    \n",
    "    processed_frame, features, hand_detected = process_frame(frame)\n",
    "    \n",
    "    status = \"âœ… Mano detectada\" if hand_detected else \"âš ï¸ No se detecta mano\"\n",
    "    non_zero = np.count_nonzero(features)\n",
    "    info = f\"{status}\\nðŸ“Š Features: {non_zero}/240\"\n",
    "    \n",
    "    return processed_frame, info\n",
    "\n",
    "def start_capture(sign_name, num_samples, frames_per_sample):\n",
    "    \"\"\"Inicia captura mÃºltiple.\"\"\"\n",
    "    if not sign_name or not sign_name.strip():\n",
    "        return \"âŒ Ingresa un nombre para la seÃ±a\", gr.update(interactive=False)\n",
    "    \n",
    "    state.capturing = True\n",
    "    state.capture_buffer = []\n",
    "    state.current_sign = sign_name.strip().lower().replace(\" \", \"_\")\n",
    "    state.total_samples = num_samples\n",
    "    state.frames_per_sample = frames_per_sample\n",
    "    state.samples_captured = 0\n",
    "    state.current_sequence = []\n",
    "    \n",
    "    return f\"âœ… Iniciando captura de '{state.current_sign}'\\nðŸŽ¯ Meta: {num_samples} muestras\\n\\nâ–¶ï¸ Muestra tu mano para empezar...\", gr.update(interactive=True)\n",
    "\n",
    "def capture_frame(frame):\n",
    "    \"\"\"Captura frame durante sesiÃ³n de captura.\"\"\"\n",
    "    if not state.capturing:\n",
    "        return frame, \"â¹ï¸ No hay captura activa\"\n",
    "    \n",
    "    if frame is None:\n",
    "        return None, \"âš ï¸ No hay frame\"\n",
    "    \n",
    "    processed_frame, features, hand_detected = process_frame(frame)\n",
    "    \n",
    "    status = f\"ðŸ“¹ Capturando: {state.current_sign}\\n\"\n",
    "    status += f\"ðŸ“Š Muestra {state.samples_captured + 1}/{state.total_samples}\\n\"\n",
    "    status += f\"ðŸ“ Frames: {len(state.current_sequence)}/{state.frames_per_sample}\\n\\n\"\n",
    "    \n",
    "    if hand_detected:\n",
    "        state.current_sequence.append(features)\n",
    "        status += \"âœ… Grabando...\\n\"\n",
    "        \n",
    "        # Completar muestra\n",
    "        if len(state.current_sequence) >= state.frames_per_sample:\n",
    "            # Guardar muestra\n",
    "            sign_dir = DATA_DIR / \"raw\" / state.current_sign\n",
    "            sign_dir.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            existing = len(list(sign_dir.glob(\"*.npy\")))\n",
    "            sequence_array = np.array(state.current_sequence[:state.frames_per_sample])\n",
    "            \n",
    "            sample_file = sign_dir / f\"sample_{existing:03d}.npy\"\n",
    "            np.save(sample_file, sequence_array)\n",
    "            \n",
    "            state.samples_captured += 1\n",
    "            state.current_sequence = []\n",
    "            \n",
    "            status += f\"âœ… Muestra {state.samples_captured} guardada!\\n\"\n",
    "            \n",
    "            # Completar todas las muestras\n",
    "            if state.samples_captured >= state.total_samples:\n",
    "                state.capturing = False\n",
    "                status += f\"\\nðŸŽ‰ COMPLETADO!\\n\"\n",
    "                status += f\"ðŸ“¦ {state.samples_captured} muestras guardadas\\n\"\n",
    "                status += f\"ðŸ“ {sign_dir}\\n\"\n",
    "            else:\n",
    "                status += f\"\\nâ¸ï¸ Pausa 1 seg - Cambia Ã¡ngulo\\n\"\n",
    "                time.sleep(1)\n",
    "    else:\n",
    "        status += \"â¸ï¸ Esperando mano...\\n\"\n",
    "    \n",
    "    return processed_frame, status\n",
    "\n",
    "def stop_capture():\n",
    "    \"\"\"Detiene captura.\"\"\"\n",
    "    state.capturing = False\n",
    "    return f\"â¹ï¸ Captura detenida\\nðŸ“Š Muestras capturadas: {state.samples_captured}/{state.total_samples}\"\n",
    "\n",
    "# ============================================================================\n",
    "# TAB 2: ENTRENAMIENTO\n",
    "# ============================================================================\n",
    "\n",
    "def train_model(epochs, batch_size, use_augmentation, progress=gr.Progress()):\n",
    "    \"\"\"Entrena el modelo.\"\"\"\n",
    "    if not TRAINING_AVAILABLE:\n",
    "        return \"âŒ MÃ³dulos de entrenamiento no disponibles\\n\\nAgrega estos archivos a tu repo:\\n- advanced_lstm_model.py\\n- training.py\\n\\nCÃ³digo en: ALL_FILES_COMPLETE_CODE.md\"\n",
    "    \n",
    "    try:\n",
    "        progress(0, desc=\"Inicializando...\")\n",
    "        \n",
    "        trainer = Trainer(\n",
    "            data_dir=DATA_DIR,\n",
    "            models_dir=MODELS_DIR,\n",
    "            use_augmentation=use_augmentation\n",
    "        )\n",
    "        \n",
    "        progress(0.1, desc=\"Cargando datos...\")\n",
    "        X, y, sign_map = trainer.load_and_prepare_data()\n",
    "        \n",
    "        if len(X) == 0:\n",
    "            return \"âŒ No hay datos. Captura algunas seÃ±as primero.\"\n",
    "        \n",
    "        state.sign_map = sign_map\n",
    "        \n",
    "        progress(0.2, desc=\"Normalizando...\")\n",
    "        X = trainer.normalize_sequence_lengths(X, target_length=30)\n",
    "        \n",
    "        progress(0.3, desc=\"Dividiendo datos...\")\n",
    "        X_train, X_val, X_test, y_train, y_val, y_test = trainer.split_data(X, y)\n",
    "        \n",
    "        if use_augmentation:\n",
    "            progress(0.4, desc=\"Data augmentation...\")\n",
    "            X_train, y_train = trainer.augment_data(X_train, y_train)\n",
    "        \n",
    "        progress(0.5, desc=\"Entrenando modelo...\")\n",
    "        model, history = trainer.train_model(\n",
    "            X_train, y_train,\n",
    "            X_val, y_val,\n",
    "            num_classes=len(sign_map),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            model_name=\"sign_language_model\"\n",
    "        )\n",
    "        \n",
    "        state.current_model = model\n",
    "        \n",
    "        progress(0.9, desc=\"Evaluando...\")\n",
    "        results = trainer.evaluate_model(model, X_test, y_test, sign_map)\n",
    "        \n",
    "        progress(1.0, desc=\"Completado\")\n",
    "        \n",
    "        output = f\"âœ… ENTRENAMIENTO COMPLETADO\\n\\n\"\n",
    "        output += f\"ðŸ“Š Dataset:\\n\"\n",
    "        output += f\"   SeÃ±as: {len(sign_map)}\\n\"\n",
    "        output += f\"   Train: {len(X_train)}\\n\"\n",
    "        output += f\"   Val: {len(X_val)}\\n\"\n",
    "        output += f\"   Test: {len(X_test)}\\n\\n\"\n",
    "        output += f\"ðŸ“ˆ Resultados:\\n\"\n",
    "        output += f\"   Accuracy: {results['metrics']['accuracy']:.2%}\\n\"\n",
    "        output += f\"   Top-3: {results['metrics'].get('top_3_accuracy', 0):.2%}\\n\\n\"\n",
    "        output += f\"ðŸ’¾ Modelo: sign_language_model_best.h5\\n\"\n",
    "        \n",
    "        return output\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"âŒ Error: {str(e)}\"\n",
    "\n",
    "# ============================================================================\n",
    "# TAB 3: TRADUCCIÃ“N\n",
    "# ============================================================================\n",
    "\n",
    "def load_model_for_translation(model_name):\n",
    "    \"\"\"Carga modelo para traducciÃ³n.\"\"\"\n",
    "    try:\n",
    "        model_path = MODELS_DIR / model_name\n",
    "        if not model_path.exists():\n",
    "            return \"âŒ Modelo no encontrado\"\n",
    "        \n",
    "        state.current_model = tf.keras.models.load_model(str(model_path))\n",
    "        \n",
    "        # Cargar sign_map\n",
    "        sign_map_path = DATA_DIR / \"processed\" / \"sign_map.json\"\n",
    "        if sign_map_path.exists():\n",
    "            with open(sign_map_path) as f:\n",
    "                state.sign_map = {int(k): v for k, v in json.load(f).items()}\n",
    "        \n",
    "        return f\"âœ… Modelo cargado: {model_name}\"\n",
    "    except Exception as e:\n",
    "        return f\"âŒ Error: {str(e)}\"\n",
    "\n",
    "def translate_sign(frame):\n",
    "    \"\"\"Traduce seÃ±a en tiempo real.\"\"\"\n",
    "    if state.current_model is None:\n",
    "        return frame, \"âš ï¸ Carga un modelo primero\"\n",
    "    \n",
    "    if frame is None:\n",
    "        return None, \"âš ï¸ No hay frame\"\n",
    "    \n",
    "    # Procesar frame\n",
    "    processed_frame, features, hand_detected = process_frame(frame)\n",
    "    \n",
    "    if not hand_detected:\n",
    "        return processed_frame, \"â¸ï¸ No se detecta mano\"\n",
    "    \n",
    "    # Acumular frames (necesitamos secuencia de 30)\n",
    "    if not hasattr(state, 'translation_buffer'):\n",
    "        state.translation_buffer = []\n",
    "    \n",
    "    state.translation_buffer.append(features)\n",
    "    \n",
    "    if len(state.translation_buffer) > 30:\n",
    "        state.translation_buffer.pop(0)\n",
    "    \n",
    "    if len(state.translation_buffer) < 30:\n",
    "        return processed_frame, f\"ðŸ“Š Acumulando frames: {len(state.translation_buffer)}/30\"\n",
    "    \n",
    "    # Predecir\n",
    "    sequence = np.array([state.translation_buffer])\n",
    "    prediction = state.current_model.predict(sequence, verbose=0)\n",
    "    predicted_class = np.argmax(prediction[0])\n",
    "    confidence = prediction[0][predicted_class]\n",
    "    \n",
    "    # Obtener nombre\n",
    "    sign_name = state.sign_map.get(predicted_class, f\"Clase {predicted_class}\")\n",
    "    \n",
    "    result = f\"ðŸ”® SeÃ±a: {sign_name.upper()}\\n\"\n",
    "    result += f\"ðŸ“Š Confianza: {confidence:.1%}\\n\\n\"\n",
    "    \n",
    "    # Top 3\n",
    "    top3_idx = np.argsort(prediction[0])[-3:][::-1]\n",
    "    result += \"Top 3:\\n\"\n",
    "    for i, idx in enumerate(top3_idx, 1):\n",
    "        name = state.sign_map.get(idx, f\"Clase {idx}\")\n",
    "        conf = prediction[0][idx]\n",
    "        result += f\"  {i}. {name}: {conf:.1%}\\n\"\n",
    "    \n",
    "    return processed_frame, result\n",
    "\n",
    "# ============================================================================\n",
    "# TAB 4: DATASET INFO\n",
    "# ============================================================================\n",
    "\n",
    "def show_dataset_info():\n",
    "    \"\"\"Muestra info del dataset.\"\"\"\n",
    "    raw_dir = DATA_DIR / \"raw\"\n",
    "    if not raw_dir.exists():\n",
    "        return \"ðŸ“­ No hay datos capturados\"\n",
    "    \n",
    "    sign_dirs = [d for d in raw_dir.iterdir() if d.is_dir()]\n",
    "    \n",
    "    if not sign_dirs:\n",
    "        return \"ðŸ“­ No hay seÃ±as capturadas\"\n",
    "    \n",
    "    output = f\"ðŸ“Š DATASET DE SEÃ‘AS\\n\" + \"=\"*50 + \"\\n\\n\"\n",
    "    output += f\"ðŸŽ¯ Total de seÃ±as: {len(sign_dirs)}\\n\\n\"\n",
    "    \n",
    "    total_samples = 0\n",
    "    \n",
    "    for sign_dir in sorted(sign_dirs):\n",
    "        samples = list(sign_dir.glob(\"*.npy\"))\n",
    "        num_samples = len(samples)\n",
    "        total_samples += num_samples\n",
    "        \n",
    "        output += f\"ðŸ“ {sign_dir.name}:\\n\"\n",
    "        output += f\"   Muestras: {num_samples}\\n\"\n",
    "        \n",
    "        if samples:\n",
    "            data = np.load(samples[0])\n",
    "            output += f\"   Shape: {data.shape}\\n\"\n",
    "        \n",
    "        if num_samples < 10:\n",
    "            output += f\"   âš ï¸  MÃ­nimo recomendado: 15\\n\"\n",
    "        elif num_samples >= 15:\n",
    "            output += f\"   âœ… Excelente\\n\"\n",
    "        else:\n",
    "            output += f\"   âœ… Aceptable\\n\"\n",
    "        \n",
    "        output += \"\\n\"\n",
    "    \n",
    "    output += \"=\"*50 + \"\\n\"\n",
    "    output += f\"ðŸ“ˆ Total muestras: {total_samples}\\n\"\n",
    "    output += f\"ðŸ“Š Promedio/seÃ±a: {total_samples / len(sign_dirs):.1f}\\n\\n\"\n",
    "    \n",
    "    # Recomendaciones\n",
    "    if len(sign_dirs) < 5:\n",
    "        output += \"ðŸ’¡ Captura al menos 5 seÃ±as diferentes\\n\"\n",
    "    if total_samples < 75:\n",
    "        output += \"ðŸ’¡ Necesitas ~75 muestras (15 por seÃ±a Ã— 5 seÃ±as)\\n\"\n",
    "    \n",
    "    return output\n",
    "\n",
    "def get_model_list():\n",
    "    \"\"\"Lista modelos disponibles.\"\"\"\n",
    "    models = [m.name for m in MODELS_DIR.glob(\"*.h5\")]\n",
    "    return models if models else [\"No hay modelos\"]\n",
    "\n",
    "# ============================================================================\n",
    "# CREAR INTERFAZ\n",
    "# ============================================================================\n",
    "\n",
    "with gr.Blocks(theme=gr.themes.Soft(), title=\"Sign Language Translator\") as demo:\n",
    "    \n",
    "    gr.Markdown(\"\"\"\n",
    "    # ðŸ¤Ÿ Sign Language Translator - COMPLETO\n",
    "    ### âœ¨ Captura â€¢ Entrenamiento â€¢ TraducciÃ³n\n",
    "    \n",
    "    **Webcam integrada en Gradio â€¢ 240 features â€¢ Bi-LSTM + Attention â€¢ Data Augmentation**\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Tabs():\n",
    "        \n",
    "        # ====================================================================\n",
    "        # TAB 1: CAPTURA\n",
    "        # ====================================================================\n",
    "        \n",
    "        with gr.Tab(\"ðŸ“¹ Captura\"):\n",
    "            gr.Markdown(\"\"\"\n",
    "            ### Captura mÃºltiple con detecciÃ³n de manos\n",
    "            \n",
    "            **Flujo:**\n",
    "            1. Autoriza webcam en tu navegador\n",
    "            2. Click \"Preview\" para verificar detecciÃ³n\n",
    "            3. Ingresa nombre de seÃ±a\n",
    "            4. Click \"Iniciar Captura\"\n",
    "            5. Muestra tu mano â†’ Graba automÃ¡ticamente\n",
    "            6. Captura mÃºltiples muestras variando Ã¡ngulos\n",
    "            \"\"\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    webcam_input = gr.Image(sources=[\"webcam\"], streaming=True, label=\"Webcam\")\n",
    "                \n",
    "                with gr.Column(scale=1):\n",
    "                    webcam_output = gr.Image(label=\"Procesado + Keypoints\")\n",
    "                    status_output = gr.Textbox(label=\"Estado\", lines=8)\n",
    "            \n",
    "            with gr.Row():\n",
    "                sign_name_input = gr.Textbox(label=\"Nombre de la SeÃ±a\", placeholder=\"Ej: hola\")\n",
    "                num_samples_input = gr.Slider(1, 30, 15, step=1, label=\"Muestras\")\n",
    "                frames_input = gr.Slider(15, 45, 30, step=5, label=\"Frames/Muestra\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                preview_btn = gr.Button(\"ðŸ‘ï¸ Preview\", variant=\"secondary\")\n",
    "                start_btn = gr.Button(\"â–¶ï¸ Iniciar Captura\", variant=\"primary\")\n",
    "                stop_btn = gr.Button(\"â¹ï¸ Detener\", variant=\"stop\")\n",
    "            \n",
    "            # Eventos\n",
    "            preview_btn.click(\n",
    "                fn=preview_webcam,\n",
    "                inputs=webcam_input,\n",
    "                outputs=[webcam_output, status_output]\n",
    "            )\n",
    "            \n",
    "            start_btn.click(\n",
    "                fn=start_capture,\n",
    "                inputs=[sign_name_input, num_samples_input, frames_input],\n",
    "                outputs=[status_output, start_btn]\n",
    "            )\n",
    "            \n",
    "            # Stream processing durante captura\n",
    "            webcam_input.stream(\n",
    "                fn=capture_frame,\n",
    "                inputs=webcam_input,\n",
    "                outputs=[webcam_output, status_output],\n",
    "                stream_every=0.1\n",
    "            )\n",
    "            \n",
    "            stop_btn.click(\n",
    "                fn=stop_capture,\n",
    "                outputs=status_output\n",
    "            )\n",
    "            \n",
    "            gr.Markdown(\"\"\"\n",
    "            **ðŸ’¡ Tips:**\n",
    "            - Captura 15-20 muestras por seÃ±a\n",
    "            - VarÃ­a Ã¡ngulos entre muestras\n",
    "            - Auto-pausa cuando no detecta manos\n",
    "            \"\"\")\n",
    "        \n",
    "        # ====================================================================\n",
    "        # TAB 2: ENTRENAMIENTO\n",
    "        # ====================================================================\n",
    "        \n",
    "        with gr.Tab(\"ðŸŽ“ Entrenamiento\"):\n",
    "            gr.Markdown(\"\"\"\n",
    "            ### Entrenar modelo Bi-LSTM + Attention\n",
    "            \"\"\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                epochs_input = gr.Slider(10, 200, 100, step=10, label=\"Ã‰pocas\")\n",
    "                batch_size_input = gr.Slider(8, 64, 16, step=8, label=\"Batch Size\")\n",
    "            \n",
    "            augmentation_check = gr.Checkbox(\n",
    "                label=\"Data Augmentation (Recomendado)\",\n",
    "                value=True\n",
    "            )\n",
    "            \n",
    "            train_btn = gr.Button(\"ðŸš€ Entrenar\", variant=\"primary\")\n",
    "            train_output = gr.Textbox(label=\"Resultados\", lines=15)\n",
    "            \n",
    "            train_btn.click(\n",
    "                fn=train_model,\n",
    "                inputs=[epochs_input, batch_size_input, augmentation_check],\n",
    "                outputs=train_output\n",
    "            )\n",
    "            \n",
    "            if not TRAINING_AVAILABLE:\n",
    "                gr.Markdown(\"\"\"\n",
    "                âš ï¸ **MÃ³dulos de entrenamiento no disponibles**\n",
    "                \n",
    "                Para habilitar entrenamiento, agrega a tu repositorio:\n",
    "                - `src/advanced_lstm_model.py`\n",
    "                - `src/training.py`\n",
    "                \n",
    "                CÃ³digo completo en: `ALL_FILES_COMPLETE_CODE.md`\n",
    "                \"\"\")\n",
    "        \n",
    "        # ====================================================================\n",
    "        # TAB 3: TRADUCCIÃ“N\n",
    "        # ====================================================================\n",
    "        \n",
    "        with gr.Tab(\"ðŸ”® TraducciÃ³n\"):\n",
    "            gr.Markdown(\"\"\"\n",
    "            ### TraducciÃ³n en tiempo real\n",
    "            \n",
    "            1. Selecciona modelo entrenado\n",
    "            2. Click \"Cargar Modelo\"\n",
    "            3. Muestra tu seÃ±a a la webcam\n",
    "            4. Observa la predicciÃ³n\n",
    "            \"\"\")\n",
    "            \n",
    "            model_selector = gr.Dropdown(\n",
    "                label=\"Modelo\",\n",
    "                choices=get_model_list(),\n",
    "                interactive=True\n",
    "            )\n",
    "            \n",
    "            load_btn = gr.Button(\"ðŸ“¥ Cargar Modelo\")\n",
    "            load_status = gr.Textbox(label=\"Estado\", lines=2)\n",
    "            \n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    translate_webcam = gr.Image(sources=[\"webcam\"], streaming=True, label=\"Webcam\")\n",
    "                \n",
    "                with gr.Column(scale=1):\n",
    "                    translate_output_img = gr.Image(label=\"Procesado\")\n",
    "                    translate_result = gr.Textbox(label=\"PredicciÃ³n\", lines=8)\n",
    "            \n",
    "            load_btn.click(\n",
    "                fn=load_model_for_translation,\n",
    "                inputs=model_selector,\n",
    "                outputs=load_status\n",
    "            )\n",
    "            \n",
    "            translate_webcam.stream(\n",
    "                fn=translate_sign,\n",
    "                inputs=translate_webcam,\n",
    "                outputs=[translate_output_img, translate_result],\n",
    "                stream_every=0.2\n",
    "            )\n",
    "            \n",
    "            demo.load(\n",
    "                fn=lambda: gr.Dropdown(choices=get_model_list()),\n",
    "                outputs=model_selector\n",
    "            )\n",
    "        \n",
    "        # ====================================================================\n",
    "        # TAB 4: DATASET INFO\n",
    "        # ====================================================================\n",
    "        \n",
    "        with gr.Tab(\"ðŸ“Š Dataset\"):\n",
    "            gr.Markdown(\"### InformaciÃ³n del Dataset\")\n",
    "            \n",
    "            refresh_btn = gr.Button(\"ðŸ”„ Actualizar\")\n",
    "            dataset_info = gr.Textbox(label=\"Dataset\", lines=20)\n",
    "            \n",
    "            refresh_btn.click(fn=show_dataset_info, outputs=dataset_info)\n",
    "            demo.load(fn=show_dataset_info, outputs=dataset_info)\n",
    "    \n",
    "    gr.Markdown(\"\"\"\n",
    "    ---\n",
    "    ### ðŸ“š InformaciÃ³n\n",
    "    \n",
    "    **ðŸ’¾ Datos**: `/content/drive/MyDrive/SignLanguageTranslator/`\n",
    "    \n",
    "    **ðŸŽ¥ Captura**: Webcam integrada en Gradio â€¢ Auto-pausa â€¢ DetecciÃ³n de manos\n",
    "    \n",
    "    **ðŸŽ“ Entrenamiento**: Bi-LSTM + Attention â€¢ Data Augmentation â€¢ GPU\n",
    "    \n",
    "    **ðŸ”® TraducciÃ³n**: Tiempo real â€¢ Top-3 predicciones â€¢ Confianza\n",
    "    \"\"\")\n",
    "\n",
    "print(\"\\nðŸŽ¨ Iniciando interfaz completa...\\n\")\n",
    "print(\"âœ… Funcionalidades:\")\n",
    "print(\"   1. Captura con webcam en Gradio\")\n",
    "print(\"   2. Entrenamiento\", \"âœ…\" if TRAINING_AVAILABLE else \"âš ï¸ (requiere archivos)\")\n",
    "print(\"   3. TraducciÃ³n en tiempo real\")\n",
    "print(\"   4. Info de dataset\\n\")\n",
    "\n",
    "demo.launch(debug=True, share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ðŸ“ Notas\n",
    "\n",
    "## âœ… Mejoras Implementadas\n",
    "\n",
    "### 1. Webcam en Gradio\n",
    "- `gr.Image(sources=[\"webcam\"], streaming=True)`\n",
    "- No necesita JavaScript de Colab\n",
    "- Se ve directamente en la interfaz\n",
    "\n",
    "### 2. Captura Completa\n",
    "- Preview en vivo\n",
    "- Captura mÃºltiple automÃ¡tica\n",
    "- DetecciÃ³n de manos con auto-pausa\n",
    "- Feedback en tiempo real\n",
    "\n",
    "### 3. Entrenamiento Funcional\n",
    "- Carga datos del dataset\n",
    "- Data augmentation\n",
    "- Entrena Bi-LSTM + Attention\n",
    "- Guarda mejor modelo\n",
    "\n",
    "### 4. TraducciÃ³n en Tiempo Real\n",
    "- Carga modelos entrenados\n",
    "- Traduce mientras muestras seÃ±as\n",
    "- Top-3 predicciones\n",
    "- Muestra confianza\n",
    "\n",
    "## ðŸŽ¯ Flujo Completo\n",
    "\n",
    "```\n",
    "1. CAPTURA (Tab 1)\n",
    "   â”œâ”€ Click \"Preview\" â†’ Ver mano + keypoints\n",
    "   â”œâ”€ Ingresar nombre: \"hola\"\n",
    "   â”œâ”€ Muestras: 15\n",
    "   â”œâ”€ Click \"Iniciar Captura\"\n",
    "   â”œâ”€ Mostrar mano â†’ Graba automÃ¡ticamente\n",
    "   â”œâ”€ Sin mano â†’ Auto-pausa\n",
    "   â””â”€ Repetir para 5+ seÃ±as\n",
    "\n",
    "2. ENTRENAMIENTO (Tab 2)\n",
    "   â”œâ”€ Ã‰pocas: 100\n",
    "   â”œâ”€ Batch: 16\n",
    "   â”œâ”€ Augmentation: âœ…\n",
    "   â”œâ”€ Click \"Entrenar\"\n",
    "   â””â”€ Esperar ~10-15 min\n",
    "\n",
    "3. TRADUCCIÃ“N (Tab 3)\n",
    "   â”œâ”€ Seleccionar modelo\n",
    "   â”œâ”€ Click \"Cargar Modelo\"\n",
    "   â”œâ”€ Mostrar seÃ±a a webcam\n",
    "   â””â”€ Ver predicciÃ³n en tiempo real\n",
    "\n",
    "4. DATASET (Tab 4)\n",
    "   â””â”€ Ver estadÃ­sticas y progreso\n",
    "```\n",
    "\n",
    "## âš ï¸ Importante\n",
    "\n",
    "**Para entrenamiento completo necesitas:**\n",
    "- `src/advanced_lstm_model.py`\n",
    "- `src/training.py`\n",
    "\n",
    "**CÃ³digo en**: `ALL_FILES_COMPLETE_CODE.md`\n",
    "\n",
    "**Si no los tienes**, la captura y traducciÃ³n funcionarÃ¡n pero entrenamiento mostrarÃ¡ mensaje de error.\n",
    "\n",
    "---\n",
    "\n",
    "**Â¡Disfruta tu Sign Language Translator completo! ðŸ¤Ÿ**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
